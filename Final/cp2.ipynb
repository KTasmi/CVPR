{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import glob as gb\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "SEED = 1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TRAIN_DIR = 'C:/Users/Asus/Downloads/archive/train'\n",
    "TEST_DIR = 'C:/Users/Asus/Downloads/archive/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5778\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "class_count = []\n",
    "train_exm = 0\n",
    "for f in os.listdir(TRAIN_DIR):\n",
    "    files = gb.glob(pathname=str(TRAIN_DIR  + '//' + f + '/*.png'))\n",
    "    categories.append(f)\n",
    "    class_count.append(len(files))\n",
    "    train_exm += len(files)\n",
    "\n",
    "sns.barplot(x=categories, y=class_count).set_title(\"distribution of train data\")\n",
    "\n",
    "plt.show()\n",
    "print(train_exm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    validation_split = 0.2,\n",
    "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "    # dtype = tf.float32\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "    # dtype = tf.float32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4624 images belonging to 5 classes.\n",
      "Found 1154 images belonging to 5 classes.\n",
      "Found 1656 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch = train_gen.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    "    subset = 'training',\n",
    "    seed = SEED\n",
    ")\n",
    "valid_batch = train_gen.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    "    subset = 'validation',\n",
    "    seed = SEED\n",
    ")\n",
    "test_batch = test_gen.flow_from_directory(\n",
    "    directory=TEST_DIR,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    "    seed = SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 58s 1us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_shape = (IMG_SIZE, IMG_SIZE) + (3,)\n",
    "base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False,  weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,142,213\n",
      "Trainable params: 15,142,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_SIZE,IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss= tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 251s 12s/step - loss: 2.8108 - accuracy: 0.2949 - val_loss: 1.4177 - val_accuracy: 0.4141\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    train_batch,\n",
    "    steps_per_epoch = 642 // BATCH_SIZE,\n",
    "    validation_data=valid_batch,\n",
    "    validation_steps=158 // BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_shape = (IMG_SIZE, IMG_SIZE) + (3,)\n",
    "base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True  \n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,142,213\n",
      "Trainable params: 15,142,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss= tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 269s 13s/step - loss: 2.8833 - accuracy: 0.3029 - val_loss: 1.4639 - val_accuracy: 0.4141\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    train_batch,\n",
    "    steps_per_epoch = 642 // BATCH_SIZE,\n",
    "    validation_data=valid_batch,\n",
    "    validation_steps=158 // BATCH_SIZE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
